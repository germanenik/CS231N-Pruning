{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple toy example\n",
    "This notebook reproduces empirically the toy example in Fig.1 on the paper. We compute attributions for the only hidden layer of the model using different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the model weights\n",
    "w1 = torch.tensor(np.array([[-0.25, 1.0, 1.0, 1.0], [0.25, -1.0, 1.0, 1.0]])).float()\n",
    "b1 =  torch.tensor(np.array([-0.,0.,0.,0.])).float()\n",
    "w2 = torch.tensor(np.array([[2], [0.5], [0.5,], [0.]])).float()\n",
    "\n",
    "# Generate some input data\n",
    "x_test = np.array([[10*np.random.random(), 10*np.random.random()] for _ in range(100)])\n",
    "y_test = np.array([[np.max(xi)] for xi in x_test])\n",
    "x_test = torch.tensor(x_test).float()\n",
    "y_test = torch.tensor(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1722183227539062\n",
      "APoZ scores: tensor([ 5056,  4944, 10000, 10000])\n",
      "Weight norm: tensor([0.5000, 2.0000, 2.0000, 2.0000])\n",
      "Gradient: tensor([4.0052, 1.0013, 1.0013, 0.2003])\n",
      "Taylor: tensor([ -1.7014,  -1.6179, -11.7222,   2.3444], grad_fn=<SumBackward1>)\n",
      "SV: [ 0.80446774  0.76193867  4.96361897 -1.044156  ]\n"
     ]
    }
   ],
   "source": [
    "def run(x):\n",
    "    z = F.relu(torch.mm(x, w1) + b1)\n",
    "    z.requires_grad = True\n",
    "    y = torch.mm(z, w2)\n",
    "    return z, y\n",
    "\n",
    "def run_last(z):\n",
    "    y = torch.mm(z, w2)\n",
    "    return y\n",
    "\n",
    "z, y = run(x_test)\n",
    "loss = F.mse_loss(y, y_test)\n",
    "print (f\"Loss: {loss}\")\n",
    "\n",
    "# APoZ\n",
    "print (f\"APoZ scores: {(z > 0.).sum(0)}\")\n",
    "\n",
    "# Weight norm\n",
    "print (f\"Weight norm: {w1.abs().sum(0)}\")\n",
    "\n",
    "# Gradient and Taylor\n",
    "loss.backward()\n",
    "print (f\"Gradient: {z.grad.abs().sum(0)}\")\n",
    "print (f\"Taylor: {(z.grad * z).sum(0)}\")\n",
    "\n",
    "# SV\n",
    "sv = np.array([0., 0., 0., 0.])\n",
    "for _ in range(20000):\n",
    "    _z = z.clone().detach()\n",
    "    _y = run_last(_z)\n",
    "    loss = F.mse_loss(_y, y_test)\n",
    "    for i in np.random.permutation(4):\n",
    "        _z.index_fill_(1, torch.tensor(np.array([i])), 0.0)\n",
    "        _y = run_last(_z)\n",
    "        new_loss = F.l1_loss(_y, y_test)\n",
    "        delta = new_loss - loss\n",
    "        sv[i] += delta.clone().detach().numpy()\n",
    "        loss = new_loss\n",
    "print (f\"SV: {sv / 20000}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
